from __future__ import unicode_literals

from nltk.corpus import stopwords

import json, os

class TwitterRecord(object):
	def __init__(self,keywords):
		self.trigger = '-'.join(keywords)
		self.filenames = [filename for filename in os.listdir('../data/') 
			if self.trigger in filename and not filename.endswith('txt')]
		
		self.tweets = [tweet['text'] for tweet in json.load(open('../data/%s'%(filename),'rb')) 
				for filename in self.filenames]

		self.textname = '../data/%s.txt'%(self.trigger)
		with open(self.textname,'wb') as f:
			for tweet in map(lambda tweet: tweet.encode('utf-8'),self.tweets):
				print>>f,tweet

'''
Can't regularlize here because WordNet lookup works better with a Part-of-Speech tag. 
This means that the text file that SemanticDistance accesses must have the entire tweet.
'''